{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Case of MultiVariate Regression ##\n",
    "\n",
    "Suppose, dependent Variable $y$ depends on 2 Independant Variables $X_1$ & $X_2$, \n",
    "<br> as <br/>\n",
    "<br> $$y = 3X_1 + 5X_2 + C$$ <br/>\n",
    "\n",
    "A Physical example would be\n",
    "\n",
    "1. $Y$ is flow rate measurement from pipe origining from 2 points. $X_1$ & $X_2$ is known flowrate measurement.\n",
    "   - $C$ is added to account for the measurement error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = torch.tensor([3, 5]) \n",
    "bias = torch.tensor([11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = torch.randn(50).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = torch.randn(50).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot = torch.stack([X_1, X_2], dim=1).squeeze(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth\n",
    "\n",
    "$$ y = 3 X_1 + 5 X_2 + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (wt * X_tot).sum(dim=1) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_tot[:train_split], y[:train_split]\n",
    "X_test, y_test = X_tot[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     input_var = 'X1',\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  input_xs_slice_num = 0 if input_var == 'X1' else 1\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data[:, input_xs_slice_num], train_labels, c=\"b\", s=4, label=\"Training data - X1\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data[:, input_xs_slice_num], test_labels, c=\"g\", s=4, label=\"Testing data - X1\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data[:, input_xs_slice_num], predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3d(x_train: torch.tensor, y_train: torch.tensor) -> go.Figure:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    :param train: _description_\n",
    "    :type train: torch.tensor\n",
    "\n",
    "    :param test: _description_\n",
    "    :type test: torch.tensor\n",
    "\n",
    "    :return: _description_\n",
    "    :rtype: go.Figure\n",
    "    \"\"\"\n",
    "\n",
    "    var_1, var_2 = x_train[:, 0] , x_train[:, 1]\n",
    "\n",
    "    y = y_train\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig = go.Figure(data =[go.Scatter3d(x = var_1,\n",
    "                                   y = var_2,\n",
    "                                   z = y_train,\n",
    "                                   mode ='markers')])\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chk \u001b[39m=\u001b[39m plot3d(x_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train)\n",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m, in \u001b[0;36mplot3d\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m     16\u001b[0m y \u001b[39m=\u001b[39m y_train\n\u001b[1;32m     18\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure()\n\u001b[0;32m---> 20\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(data \u001b[39m=\u001b[39m[go\u001b[39m.\u001b[39;49mScatter3d(x \u001b[39m=\u001b[39;49m var_1,\n\u001b[1;32m     21\u001b[0m                                y \u001b[39m=\u001b[39;49m var_2,\n\u001b[1;32m     22\u001b[0m                                z \u001b[39m=\u001b[39;49m y_train,\n\u001b[1;32m     23\u001b[0m                                mode \u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmarkers\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m fig\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/graph_objs/_scatter3d.py:2758\u001b[0m, in \u001b[0;36mScatter3d.__init__\u001b[0;34m(self, arg, connectgaps, customdata, customdatasrc, error_x, error_y, error_z, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, legend, legendgroup, legendgrouptitle, legendrank, legendwidth, line, marker, meta, metasrc, mode, name, opacity, projection, scene, showlegend, stream, surfaceaxis, surfacecolor, text, textfont, textposition, textpositionsrc, textsrc, texttemplate, texttemplatesrc, uid, uirevision, visible, x, xcalendar, xhoverformat, xsrc, y, ycalendar, yhoverformat, ysrc, z, zcalendar, zhoverformat, zsrc, **kwargs)\u001b[0m\n\u001b[1;32m   2756\u001b[0m _v \u001b[39m=\u001b[39m x \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m _v\n\u001b[1;32m   2757\u001b[0m \u001b[39mif\u001b[39;00m _v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2758\u001b[0m     \u001b[39mself\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m _v\n\u001b[1;32m   2759\u001b[0m _v \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mxcalendar\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   2760\u001b[0m _v \u001b[39m=\u001b[39m xcalendar \u001b[39mif\u001b[39;00m xcalendar \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m _v\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:4873\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4869\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4871\u001b[0m     \u001b[39m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4872\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4873\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_prop(prop, value)\n\u001b[1;32m   4874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4875\u001b[0m     \u001b[39m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4876\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:5212\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5209\u001b[0m validator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 5212\u001b[0m     val \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39;49mvalidate_coerce(val)\n\u001b[1;32m   5213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   5214\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:398\u001b[0m, in \u001b[0;36mDataArrayValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     \u001b[39m# Pass None through\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m \u001b[39melif\u001b[39;00m is_homogeneous_array(v):\n\u001b[1;32m    399\u001b[0m     v \u001b[39m=\u001b[39m copy_to_readonly_numpy_array(v)\n\u001b[1;32m    400\u001b[0m \u001b[39melif\u001b[39;00m is_simple_array(v):\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/_plotly_utils/basevalidators.py:192\u001b[0m, in \u001b[0;36mis_homogeneous_array\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    190\u001b[0m np \u001b[39m=\u001b[39m get_module(\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, should_load\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m np:\n\u001b[0;32m--> 192\u001b[0m     v_numpy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(v)\n\u001b[1;32m    193\u001b[0m     \u001b[39m# v is essentially a scalar and so shouldn't count as an array\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m v_numpy\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m ():\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "chk = plot3d(x_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chk\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:3409\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3377\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> 3409\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/io/_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "chk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Linear Regression Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1067])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    \"\"\"Linear Regression \n",
    "\n",
    "    :param nn: _description_\n",
    "    :type nn: _type_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(2, \n",
    "                                                dtype=torch.float), \n",
    "                                                requires_grad=True)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1, \n",
    "                                             dtype=torch.float), \n",
    "                                             requires_grad=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return (self.weights * x).sum(dim=1) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115607c10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3722,  0.4445, -0.0120,  0.0370,  0.5946, -0.0324,  0.6889,  0.4123,\n",
       "         0.1748,  0.5201], device='mps:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Loss Functions & Weights Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367, 0.1288], device='mps:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2345], device='mps:0', requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function ##\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Optimizer #\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367, 0.1288], device='mps:0')),\n",
       "             ('bias', tensor([0.2345], device='mps:0'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshkumarsharma/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning:\n",
      "\n",
      "The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | Loss: 12.286921501159668 | Test Loss: 11.980545043945312\n",
      " Epoch: 1000 | Loss: 2.1239147186279297 | Test Loss: 2.0755507946014404\n",
      " Epoch: 2000 | Loss: 0.006426775362342596 | Test Loss: 0.004069996066391468\n",
      " Epoch: 3000 | Loss: 0.006426775362342596 | Test Loss: 0.004069996066391468\n",
      " Epoch: 4000 | Loss: 0.006426775362342596 | Test Loss: 0.004069996066391468\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ## Put Model into Training Mode\n",
    "    model_0.train()\n",
    "\n",
    "    ## 1. Forward Pass on Train Data using the forward() method\n",
    "\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. Calculate the loss for an entire Eporch #\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer Zero Grad. At Each Epoch change in parameters is set to 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Calculate wts increment via Back Prop\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the Optimizer (Perform Gradient Descent)\n",
    "    optimizer.step() # How Optimizer changes will acculumate \n",
    "\n",
    "    ### Testing / Evaluate\n",
    "\n",
    "    model_0.eval() ## Turns off different settings in model that is not relevent for training\n",
    "    \n",
    "    with torch.inference_mode(): ## Turns of Gradient Tracking \n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\" Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colab_ssh\n",
      "  Downloading colab_ssh-0.3.27-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: colab_ssh\n",
      "Successfully installed colab_ssh-0.3.27\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from colab_ssh import launch_ssh\n",
    "launch_ssh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.3136, 13.2880, 15.3493,  8.7775,  1.4544, 17.1985,  9.2931, 17.4443,\n",
       "         9.2918, 12.2589])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrderedDict([('weights', tensor([-0.2138])), ('bias', tensor([-1.3780]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0052)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_preds_new - y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([3.0023, 4.9957])),\n",
       "             ('bias', tensor([10.9969]))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([3.0023, 4.9957], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([10.9969], requires_grad=True)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Folder to Write PyTorch Model ##\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "## 1. Create Models Directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Create Model Save Path\n",
    "MODEL_NAME = \"01_pytorch_workflow_MultiVarModel_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH /MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Save the Model State Dict\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Saved PyTorch Model\n",
    "\n",
    "> Model's `state_dict()` contains the learned paramters, so instead of saving entire PyTorch Model, we create a instance of model and pass the `state_dict()`\n",
    "\n",
    "`Disadvantage of saving Whole Model is that the serialized data is bound to the specific classes and the exact directory structure when the model is saved.. Making likely that the Code Will Break if refractor is done` `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_reg_mod = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading State Dict of the Saved Model \n",
    "## Essentially Updating the state dict (Which are Random) of Model with Learned State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_params_dict = torch.load(f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([3.0023, 4.9957])),\n",
       "             ('bias', tensor([10.9969]))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_reg_mod.load_state_dict(learned_params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Prediction Out of The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set Model into eval Mode. This Disables Drop Out , BatchNorm Layers\n",
    "loaded_reg_mod.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_reg_mod(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.3085, 13.2820, 15.3403,  8.7725,  1.4586, 17.1927,  9.2918, 17.4378,\n",
       "         9.2929, 12.2516])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_preds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_new == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = nn.Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[0.5224, 0.0958]])),\n",
       "             ('bias', tensor([0.3410]))])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
