{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Case of MultiVariate Regression ##\n",
    "\n",
    "Suppose, dependent Variable $y$ depends on 2 Independant Variables $X_1$ & $X_2$, \n",
    "<br> as <br/>\n",
    "<br> $$y = 3X_1 + 5X_2 + C$$ <br/>\n",
    "\n",
    "A Physical example would be\n",
    "\n",
    "1. $Y$ is flow rate measurement from pipe origining from 2 points. $X_1$ & $X_2$ is known flowrate measurement.\n",
    "   - $C$ is added to account for the measurement error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = torch.tensor([3, 5]) \n",
    "bias = torch.tensor([11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = torch.randn(50).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = torch.randn(50).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot = torch.stack([X_1, X_2], dim=1).squeeze(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth\n",
    "\n",
    "$$ y = 3 X_1 + 5 X_2 + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (wt * X_tot).sum(dim=1) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_tot[:train_split], y[:train_split]\n",
    "X_test, y_test = X_tot[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     input_var = 'X1',\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  input_xs_slice_num = 0 if input_var == 'X1' else 1\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data[:, input_xs_slice_num], train_labels, c=\"b\", s=4, label=\"Training data - X1\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data[:, input_xs_slice_num], test_labels, c=\"g\", s=4, label=\"Testing data - X1\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data[:, input_xs_slice_num], predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3d(x_train: torch.tensor, y_train: torch.tensor) -> go.Figure:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    :param train: _description_\n",
    "    :type train: torch.tensor\n",
    "\n",
    "    :param test: _description_\n",
    "    :type test: torch.tensor\n",
    "\n",
    "    :return: _description_\n",
    "    :rtype: go.Figure\n",
    "    \"\"\"\n",
    "\n",
    "    var_1, var_2 = x_train[:, 0] , x_train[:, 1]\n",
    "\n",
    "    y = y_train\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig = go.Figure(data =[go.Scatter3d(x = var_1,\n",
    "                                   y = var_2,\n",
    "                                   z = y_train,\n",
    "                                   mode ='markers')])\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = plot3d(x_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chk\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/basedatatypes.py:3409\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3377\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> 3409\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/plotly/io/_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "chk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Linear Regression Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1043])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModelV2(nn.Module):\n",
    "    \"\"\"Linear Regression \n",
    "\n",
    "    :param nn: _description_\n",
    "    :type nn: _type_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModelV2, self).__init__()\n",
    "\n",
    "        ## Using nn.linear_layer, instead of nn.Parameter\n",
    "        self.linear_layer = nn.Linear(in_features=2, out_features=1, bias=True)\n",
    "\n",
    "    ## Definininf the Computation ##\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = LinearRegressionModelV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModelV2(\n",
       "   (linear_layer): Linear(in_features=2, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[-0.5116, -0.6759]])),\n",
       "              ('linear_layer.bias', tensor([0.0033]))]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0, model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModelV2(\n",
       "  (linear_layer): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Loss Functions & Weights Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function ##\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Optimizer #\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshkumarsharma/Desktop/AI/PyTorch/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning:\n",
      "\n",
      "The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 | Loss: 10.291650772094727 | Test Loss: 10.420129776000977\n",
      " Epoch: 1000 | Loss: 3.832534074783325 | Test Loss: 3.7687013149261475\n",
      " Epoch: 2000 | Loss: 0.005859649274498224 | Test Loss: 0.004499626345932484\n",
      " Epoch: 3000 | Loss: 0.005859649274498224 | Test Loss: 0.004499626345932484\n",
      " Epoch: 4000 | Loss: 0.005859649274498224 | Test Loss: 0.004499626345932484\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ## Put Model into Training Mode\n",
    "    model_0.train()\n",
    "\n",
    "    ## 1. Forward Pass on Train Data using the forward() method\n",
    "\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. Calculate the loss for an entire Eporch #\n",
    "    loss = loss_fn(y_pred, y_train.unsqueeze(dim=1))\n",
    "\n",
    "    # 3. Optimizer Zero Grad. At Each Epoch change in parameters is set to 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Calculate wts increment via Back Prop\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the Optimizer (Perform Gradient Descent)\n",
    "    optimizer.step() # How Optimizer changes will acculumate \n",
    "\n",
    "    ### Testing / Evaluate\n",
    "\n",
    "    model_0.eval() ## Turns off different settings in model that is not relevent for training\n",
    "    \n",
    "    with torch.inference_mode(): ## Turns of Gradient Tracking \n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        test_loss = loss_fn(test_pred, y_test.unsqueeze(dim=1))\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\" Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6000+0.8000j, 0.2800-0.9600j, 0.0000+0.0000j, 0.4472+0.8944j],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.tensor([3+4j, 7-24j, 0, 1+2j], device=\"mps\")\n",
    "t.sgn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrderedDict([('weights', tensor([-0.2138])), ('bias', tensor([-1.3780]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(y_preds_new - y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Folder to Write PyTorch Model ##\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "## 1. Create Models Directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Create Model Save Path\n",
    "MODEL_NAME = \"01_pytorch_workflow_MultiVarModel_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH /MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Save the Model State Dict\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Saved PyTorch Model\n",
    "\n",
    "> Model's `state_dict()` contains the learned paramters, so instead of saving entire PyTorch Model, we create a instance of model and pass the `state_dict()`\n",
    "\n",
    "`Disadvantage of saving Whole Model is that the serialized data is bound to the specific classes and the exact directory structure when the model is saved.. Making likely that the Code Will Break if refractor is done` `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_reg_mod = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading State Dict of the Saved Model \n",
    "## Essentially Updating the state dict (Which are Random) of Model with Learned State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_params_dict = torch.load(f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_reg_mod.load_state_dict(learned_params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Prediction Out of The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set Model into eval Mode. This Disables Drop Out , BatchNorm Layers\n",
    "loaded_reg_mod.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_reg_mod(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_preds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_new == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = nn.Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
